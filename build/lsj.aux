\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\babel@aux{english}{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Preface}{ix}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Background}{1}{part.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Why do we learn statistics?~}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:whystats}{{1}{3}{Why do we learn statistics?~}{chapter.1}{}}
\newlabel{sec:whywhywhy}{{1.1}{3}{On the psychology of statistics~\label {sec:whywhywhy}}{section.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}On the psychology of statistics~}{3}{section.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}The curse of belief bias}{4}{subsection.1.1.1}\protected@file@percent }
\abx@aux@cite{Evans1983}
\abx@aux@segm{0}{0}{Evans1983}
\abx@aux@backref{1}{Evans1983}{0}{5}{5}
\abx@aux@page{1}{5}
\abx@aux@cite{Bickel1975}
\abx@aux@segm{0}{0}{Bickel1975}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}The cautionary tale of Simpson's paradox}{6}{section.1.2}\protected@file@percent }
\abx@aux@backref{2}{Bickel1975}{0}{6}{6}
\abx@aux@page{2}{6}
\abx@aux@segm{0}{0}{Bickel1975}
\abx@aux@segm{0}{0}{Bickel1975}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The Berkeley 1973 college admissions data.}}{8}{figure.1.1}\protected@file@percent }
\abx@aux@backref{4}{Bickel1975}{0}{8}{8}
\newlabel{fig:berkeley}{{1.1}{8}{The Berkeley 1973 college admissions data}{figure.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Statistics in psychology}{9}{section.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.4}Statistics in everyday life}{11}{section.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.5}There's more to research methods than statistics}{11}{section.1.5}\protected@file@percent }
\abx@aux@cite{Campbell1963}
\abx@aux@segm{0}{0}{Campbell1963}
\abx@aux@cite{Stevens1946}
\abx@aux@segm{0}{0}{Stevens1946}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}A brief introduction to research design}{13}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:studydesign}{{2}{13}{A brief introduction to research design}{chapter.2}{}}
\abx@aux@backref{5}{Campbell1963}{0}{13}{13}
\abx@aux@page{5}{13}
\abx@aux@backref{6}{Stevens1946}{0}{13}{13}
\abx@aux@page{6}{13}
\newlabel{sec:measurement}{{2.1}{13}{Introduction to psychological measurement~\label {sec:measurement}}{section.2.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction to psychological measurement~}{13}{section.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Some thoughts about psychological measurement}{13}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Operationalisation: defining your measurement}{15}{subsection.2.1.2}\protected@file@percent }
\newlabel{sec:scales}{{2.2}{16}{Scales of measurement\label {sec:scales}}{section.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Scales of measurement}{16}{section.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Nominal scale}{17}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Ordinal scale}{17}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Interval scale}{19}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Ratio scale}{19}{subsection.2.2.4}\protected@file@percent }
\newlabel{sec:continuousdiscrete}{{2.2.5}{19}{Continuous versus discrete variables~\label {sec:continuousdiscrete}}{subsection.2.2.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Continuous versus discrete variables~}{19}{subsection.2.2.5}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The relationship between the scales of measurement and the discrete/continuity distinction. Cells with a tick mark correspond to things that are possible.}}{20}{table.2.1}\protected@file@percent }
\newlabel{tab:scalescont}{{2.1}{20}{The relationship between the scales of measurement and the discrete/continuity distinction. Cells with a tick mark correspond to things that are possible}{table.2.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Some complexities}{20}{subsection.2.2.6}\protected@file@percent }
\newlabel{sec:reliability}{{2.3}{22}{Assessing the reliability of a measurement~\label {sec:reliability}}{section.2.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Assessing the reliability of a measurement~}{22}{section.2.3}\protected@file@percent }
\newlabel{sec:ivdv}{{2.4}{23}{The \texorpdfstring {``role''}{role} of variables: predictors and outcomes \label {sec:ivdv}}{section.2.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}The ``role'' of variables: predictors and outcomes }{23}{section.2.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces The terminology used to distinguish between different roles that a variable can play when analysing a data set. Note that this book will tend to avoid the classical terminology in favour of the newer names.}}{24}{table.2.2}\protected@file@percent }
\newlabel{tab:ivdv}{{2.2}{24}{The terminology used to distinguish between different roles that a variable can play when analysing a data set. Note that this book will tend to avoid the classical terminology in favour of the newer names}{table.2.2}{}}
\newlabel{sec:researchdesigns}{{2.5}{24}{Experimental and non-experimental research~\label {sec:researchdesigns}}{section.2.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Experimental and non-experimental research~}{24}{section.2.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Experimental research}{24}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Non-experimental research}{25}{subsection.2.5.2}\protected@file@percent }
\newlabel{sec:validity}{{2.6}{26}{Assessing the validity of a study~\label {sec:validity}}{section.2.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.6}Assessing the validity of a study~}{26}{section.2.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Internal validity}{26}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}External validity}{27}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Construct validity}{28}{subsection.2.6.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Face validity}{28}{subsection.2.6.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.5}Ecological validity}{29}{subsection.2.6.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.7}Confounds, artefacts and other threats to validity}{29}{section.2.7}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}History effects}{30}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Maturation effects}{31}{subsection.2.7.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Repeated testing effects}{31}{subsection.2.7.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.4}Selection bias}{32}{subsection.2.7.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.5}Differential attrition}{32}{subsection.2.7.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.6}Non-response bias}{33}{subsection.2.7.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.7}Regression to the mean}{33}{subsection.2.7.7}\protected@file@percent }
\abx@aux@cite{Kahneman1973}
\abx@aux@segm{0}{0}{Kahneman1973}
\abx@aux@cite{Pfungst1911}
\abx@aux@segm{0}{0}{Pfungst1911}
\abx@aux@cite{Hothersall2004}
\abx@aux@segm{0}{0}{Hothersall2004}
\abx@aux@backref{7}{Kahneman1973}{0}{34}{34}
\abx@aux@page{7}{34}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.8}Experimenter bias}{34}{subsection.2.7.8}\protected@file@percent }
\abx@aux@backref{8}{Pfungst1911}{0}{34}{34}
\abx@aux@page{8}{34}
\abx@aux@backref{9}{Hothersall2004}{0}{34}{34}
\abx@aux@page{9}{34}
\abx@aux@cite{Rosenthal1966}
\abx@aux@segm{0}{0}{Rosenthal1966}
\abx@aux@cite{Adair1984}
\abx@aux@segm{0}{0}{Adair1984}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.9}Demand effects and reactivity}{35}{subsection.2.7.9}\protected@file@percent }
\abx@aux@backref{10}{Rosenthal1966}{0}{35}{35}
\abx@aux@page{10}{35}
\abx@aux@backref{11}{Adair1984}{0}{35}{35}
\abx@aux@page{11}{35}
\abx@aux@cite{hrobjartsson2010}
\abx@aux@segm{0}{0}{hrobjartsson2010}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.10}Placebo effects}{36}{subsection.2.7.10}\protected@file@percent }
\abx@aux@backref{12}{hrobjartsson2010}{0}{36}{36}
\abx@aux@page{12}{36}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.11}Situation, measurement and sub-population effects}{36}{subsection.2.7.11}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.12}Fraud, deception and self-deception}{36}{subsection.2.7.12}\protected@file@percent }
\abx@aux@cite{Gelman2014}
\abx@aux@segm{0}{0}{Gelman2014}
\abx@aux@cite{Ioannidis2005}
\abx@aux@segm{0}{0}{Ioannidis2005}
\abx@aux@cite{Kuhberger2014}
\abx@aux@segm{0}{0}{Kuhberger2014}
\abx@aux@backref{13}{Gelman2014}{0}{38}{38}
\abx@aux@page{13}{38}
\abx@aux@backref{14}{Ioannidis2005}{0}{38}{38}
\abx@aux@page{14}{38}
\abx@aux@backref{15}{Kuhberger2014}{0}{38}{38}
\abx@aux@page{15}{38}
\abx@aux@segm{0}{0}{Campbell1963}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.8}Summary}{39}{section.2.8}\protected@file@percent }
\abx@aux@backref{16}{Campbell1963}{0}{39}{39}
\abx@aux@page{16}{39}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {part}{II\hspace  {1em}An introduction to JASP}{41}{part.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Getting started with JASP}{43}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:introj}{{3}{43}{Getting started with JASP}{chapter.3}{}}
\newlabel{sec:gettingjasp}{{3.1}{44}{Installing JASP \label {sec:gettingjasp}}{section.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Installing JASP }{44}{section.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Starting up JASP}{44}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces JASP looks like this when you start it.}}{45}{figure.3.1}\protected@file@percent }
\newlabel{fig:startingjasp}{{3.1}{45}{JASP looks like this when you start it}{figure.3.1}{}}
\newlabel{sec:analyses}{{3.2}{45}{Analyses\label {sec:analyses}}{section.3.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Analyses}{45}{section.3.2}\protected@file@percent }
\newlabel{sec:load}{{3.3}{46}{Loading data in JASP\label {sec:load}}{section.3.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Loading data in JASP}{46}{section.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Importing data from CSV files}{46}{subsection.3.3.1}\protected@file@percent }
\newlabel{sec:spreadsheet}{{3.4}{46}{The spreadsheet\label {sec:spreadsheet}}{section.3.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}The spreadsheet}{46}{section.3.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The \texttt  {booksales.csv} data file. On the left I've opened the file using a spreadsheet program, which shows that the file is basically a table. On the right the same file is open in a standard text editor (the TextEdit program on a Mac), which shows how the file is formatted. The entries in the table are separated by commas.}}{47}{figure.3.2}\protected@file@percent }
\newlabel{fig:booksalescsv}{{3.2}{47}{The \filename {booksales.csv} data file. On the left I've opened the file using a spreadsheet program, which shows that the file is basically a table. On the right the same file is open in a standard text editor (the TextEdit program on a Mac), which shows how the file is formatted. The entries in the table are separated by commas}{figure.3.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A dialog box on a Mac asking you to select the CSV file JASP should try to import. Mac users will recognise this immediately -- it's the usual way in which a Mac asks you to find a file. Windows users won't see this, but instead will see the usual explorer window that Windows always gives you when it wants you to select a file.}}{48}{figure.3.3}\protected@file@percent }
\newlabel{fig:fileopen}{{3.3}{48}{A dialog box on a Mac asking you to select the CSV file JASP should try to import. Mac users will recognise this immediately -- it's the usual way in which a Mac asks you to find a file. Windows users won't see this, but instead will see the usual explorer window that Windows always gives you when it wants you to select a file}{figure.3.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Variables}{48}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Computed variables}{49}{subsection.3.4.2}\protected@file@percent }
\newlabel{sec:copypaste}{{3.4.3}{49}{Copy and Paste\label {sec:copypaste}}{subsection.3.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Copy and Paste}{49}{subsection.3.4.3}\protected@file@percent }
\newlabel{sec:coercion}{{3.5}{49}{Changing data from one measurement scale to another\label {sec:coercion}}{section.3.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Changing data from one measurement scale to another}{49}{section.3.5}\protected@file@percent }
\newlabel{sec:quittingjasp}{{3.6}{50}{Quitting JASP \label {sec:quittingjasp}}{section.3.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.6}Quitting JASP }{50}{section.3.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.7}Summary}{50}{section.3.7}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {part}{III\hspace  {1em}Working with data}{51}{part.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Descriptive statistics}{53}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:descriptives}{{4}{53}{Descriptive statistics}{chapter.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces A screenshot of JASP showing the variables stored in the \texttt  {aflsmall\_margins.csv} file}}{53}{figure.4.1}\protected@file@percent }
\newlabel{fig:aflsmall}{{4.1}{53}{A screenshot of JASP showing the variables stored in the \filename {aflsmall\_margins.csv} file}{figure.4.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces A histogram of the AFL 2010 winning margin data (the \texttt  {afl.margins} varable). As you might expect, the larger the winning margin the less frequently you tend to see it.}}{54}{figure.4.2}\protected@file@percent }
\newlabel{fig:histogram1}{{4.2}{54}{A histogram of the AFL 2010 winning margin data (the \texttt {afl.margins} varable). As you might expect, the larger the winning margin the less frequently you tend to see it}{figure.4.2}{}}
\newlabel{sec:centraltendency}{{4.1}{55}{Measures of central tendency~\label {sec:centraltendency}}{section.4.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Measures of central tendency~}{55}{section.4.1}\protected@file@percent }
\newlabel{sec:mean}{{4.1.1}{55}{The mean\label {sec:mean}}{subsection.4.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}The mean}{55}{subsection.4.1.1}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-1}{\default{4.1}\page{56}\abspage{68}\mdf@pagevalue{56}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Calculating the mean in JASP}{56}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Default descriptives for the AFL 2010 winning margin data (the \texttt  {afl.margins} variable). }}{57}{figure.4.3}\protected@file@percent }
\newlabel{fig:descriptives_default}{{4.3}{57}{Default descriptives for the AFL 2010 winning margin data (the \texttt {afl.margins} variable)}{figure.4.3}{}}
\newlabel{sec:median}{{4.1.3}{57}{The median\label {sec:median}}{subsection.4.1.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}The median}{57}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Mean or median? What's the difference?}{58}{subsection.4.1.4}\protected@file@percent }
\newlabel{sec:housingpriceexample}{{4.1.5}{58}{A real life example~\label {sec:housingpriceexample}}{subsection.4.1.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}A real life example~}{58}{subsection.4.1.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces An illustration of the difference between how the mean and the median should be interpreted. The mean is basically the ``centre of gravity'' of the data set. If you imagine that the histogram of the data is a solid object, then the point on which you could balance it (as if on a see-saw) is the mean. In contrast, the median is the middle observation, with half of the observations smaller and half of the observations larger.}}{59}{figure.4.4}\protected@file@percent }
\newlabel{fig:meanmedian}{{4.4}{59}{An illustration of the difference between how the mean and the median should be interpreted. The mean is basically the ``centre of gravity'' of the data set. If you imagine that the histogram of the data is a solid object, then the point on which you could balance it (as if on a see-saw) is the mean. In contrast, the median is the middle observation, with half of the observations smaller and half of the observations larger}{figure.4.4}{}}
\newlabel{sec:mode}{{4.1.6}{60}{Mode\label {sec:mode}}{subsection.4.1.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.6}Mode}{60}{subsection.4.1.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces A screenshot of JASP showing the variables stored in the \texttt  {aflsmall\_finalists.csv} file}}{61}{figure.4.5}\protected@file@percent }
\newlabel{fig:aflsmall_finalists}{{4.5}{61}{A screenshot of JASP showing the variables stored in the \filename {aflsmall\_finalists.csv} file}{figure.4.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces A screenshot of JASP showing the frequency table for the \texttt  {afl.finalists} variable }}{61}{figure.4.6}\protected@file@percent }
\newlabel{fig:aflsmall_finalists_mode}{{4.6}{61}{A screenshot of JASP showing the frequency table for the \texttt {afl.finalists} variable}{figure.4.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces A screenshot of JASP showing the modal value for the \texttt  {afl.margins} variable }}{62}{figure.4.7}\protected@file@percent }
\newlabel{fig:aflsmall_margins_mode}{{4.7}{62}{A screenshot of JASP showing the modal value for the \texttt {afl.margins} variable}{figure.4.7}{}}
\newlabel{sec:var}{{4.2}{63}{Measures of variability\label {sec:var}}{section.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Measures of variability}{63}{section.4.2}\protected@file@percent }
\newlabel{sec:range}{{4.2.1}{63}{Range\label {sec:range}}{subsection.4.2.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Range}{63}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Interquartile range}{63}{subsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces A screenshot of JASP showing the Quartiles for the \texttt  {afl.margins} variable }}{64}{figure.4.8}\protected@file@percent }
\newlabel{fig:aflsmall_margins_iqr}{{4.8}{64}{A screenshot of JASP showing the Quartiles for the \texttt {afl.margins} variable}{figure.4.8}{}}
\newlabel{sec:aad}{{4.2.3}{64}{Mean absolute deviation~\label {sec:aad}}{subsection.4.2.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Mean absolute deviation~}{64}{subsection.4.2.3}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-2}{\default{4.2}\page{65}\abspage{77}\mdf@pagevalue{65}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Variance}{65}{subsection.4.2.4}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-3}{\default{4.2}\page{66}\abspage{78}\mdf@pagevalue{66}}
\zref@newlabel{mdf@pagelabel-4}{\default{4.2}\page{67}\abspage{79}\mdf@pagevalue{67}}
\newlabel{sec:sd}{{4.2.5}{68}{Standard deviation\label {sec:sd}}{subsection.4.2.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Standard deviation}{68}{subsection.4.2.5}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-5}{\default{4.2}\page{68}\abspage{80}\mdf@pagevalue{68}}
\zref@newlabel{mdf@pagelabel-6}{\default{4.2}\page{68}\abspage{80}\mdf@pagevalue{68}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces An illustration of the standard deviation from the AFL winning margins data. The shaded bars in the histogram show how much of the data fall within one standard deviation of the mean. In this case, 65.3\% of the data set lies within this range, which is pretty consistent with the ``approximately 68\% rule'' discussed in the main text.}}{69}{figure.4.9}\protected@file@percent }
\newlabel{fig:aflsd}{{4.9}{69}{An illustration of the standard deviation from the AFL winning margins data. The shaded bars in the histogram show how much of the data fall within one standard deviation of the mean. In this case, 65.3\% of the data set lies within this range, which is pretty consistent with the ``approximately 68\% rule'' discussed in the main text}{figure.4.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Which measure to use?}{69}{subsection.4.2.6}\protected@file@percent }
\newlabel{sec:skewkurt}{{4.3}{70}{Skew and kurtosis \label {sec:skewkurt}}{section.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Skew and kurtosis }{70}{section.4.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces An illustration of skewness. On the left we have a negatively skewed data set (skewness $= -.93$), in the middle we have a data set with no skew (well, hardly any: skewness $= -.006$), and on the right we have a positively skewed data set (skewness $= .93$). }}{70}{figure.4.10}\protected@file@percent }
\newlabel{fig:skewness}{{4.10}{70}{An illustration of skewness. On the left we have a negatively skewed data set (skewness $= -.93$), in the middle we have a data set with no skew (well, hardly any: skewness $= -.006$), and on the right we have a positively skewed data set (skewness $= .93$)}{figure.4.10}{}}
\zref@newlabel{mdf@pagelabel-7}{\default{4.3}\page{71}\abspage{83}\mdf@pagevalue{71}}
\zref@newlabel{mdf@pagelabel-8}{\default{4.3}\page{71}\abspage{83}\mdf@pagevalue{71}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces An illustration of kurtosis. On the left, we have a ``platykurtic'' data set (kurtosis = $-.95$) meaning that the data set is ``too flat''. In the middle we have a ``mesokurtic'' data set (kurtosis is almost exactly 0) which means that the pointiness of the data is just about right. Finally, on the right, we have a ``leptokurtic'' data set (kurtosis $= 2.12$) indicating that the data set is ``too pointy''. Note that kurtosis is measured with respect to a normal curve (black line).}}{72}{figure.4.11}\protected@file@percent }
\newlabel{fig:kurtosis}{{4.11}{72}{An illustration of kurtosis. On the left, we have a ``platykurtic'' data set (kurtosis = $-.95$) meaning that the data set is ``too flat''. In the middle we have a ``mesokurtic'' data set (kurtosis is almost exactly 0) which means that the pointiness of the data is just about right. Finally, on the right, we have a ``leptokurtic'' data set (kurtosis $= 2.12$) indicating that the data set is ``too pointy''. Note that kurtosis is measured with respect to a normal curve (black line)}{figure.4.11}{}}
\newlabel{sec:groupdescriptives}{{4.4}{72}{Descriptive statistics separately for each group~\label {sec:groupdescriptives}}{section.4.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Descriptive statistics separately for each group~}{72}{section.4.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces A screenshot of JASP showing the variables stored in the \texttt  {clinicaltrial.csv} file}}{73}{figure.4.12}\protected@file@percent }
\newlabel{fig:clinicaltrial}{{4.12}{73}{A screenshot of JASP showing the variables stored in the \filename {clinicaltrial.csv} file}{figure.4.12}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces A screenshot of JASP showing Descriptives split by therapy type}}{74}{figure.4.13}\protected@file@percent }
\newlabel{fig:clinicaltrial_grouping}{{4.13}{74}{A screenshot of JASP showing Descriptives split by therapy type}{figure.4.13}{}}
\newlabel{sec:zscore}{{4.5}{74}{Standard scores~\label {sec:zscore}}{section.4.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Standard scores~}{74}{section.4.5}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-9}{\default{4.5}\page{75}\abspage{87}\mdf@pagevalue{75}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.6}Summary}{76}{section.4.6}\protected@file@percent }
\abx@aux@cite{Ellman2002}
\abx@aux@segm{0}{0}{Ellman2002}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Epilogue: Good descriptive statistics are descriptive!}{77}{subsection.4.6.1}\protected@file@percent }
\abx@aux@backref{17}{Ellman2002}{0}{77}{77}
\abx@aux@page{17}{77}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Drawing graphs}{79}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:graphics}{{5}{79}{Drawing graphs}{chapter.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A stylised redrawing of John Snow's original cholera map. Each small dot represents the location of a cholera case and each large circle shows the location of a well. As the plot makes clear, the cholera outbreak is centred very closely on the Broad St pump.}}{80}{figure.5.1}\protected@file@percent }
\newlabel{fig:snowmap1}{{5.1}{80}{A stylised redrawing of John Snow's original cholera map. Each small dot represents the location of a cholera case and each large circle shows the location of a well. As the plot makes clear, the cholera outbreak is centred very closely on the Broad St pump}{figure.5.1}{}}
\newlabel{sec:hist}{{5.1}{80}{Histograms\label {sec:hist}}{section.5.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Histograms}{80}{section.5.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces JASP screenshot showing the `Distribution plots' option and accompanying histogram.}}{81}{figure.5.2}\protected@file@percent }
\newlabel{fig:jasp_histogram}{{5.2}{81}{JASP screenshot showing the `Distribution plots' option and accompanying histogram}{figure.5.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces A density plot of the \texttt  {afl.margins} variable plotted in JASP}}{82}{figure.5.3}\protected@file@percent }
\newlabel{fig:histogram2}{{5.3}{82}{A density plot of the \texttt {afl.margins} variable plotted in JASP}{figure.5.3}{}}
\newlabel{sec:boxplots}{{5.2}{82}{Boxplots~\label {sec:boxplots}}{section.5.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Boxplots~}{82}{section.5.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces A box plot of the \texttt  {afl.margins} variable plotted in JASP}}{83}{figure.5.4}\protected@file@percent }
\newlabel{fig:boxplot1}{{5.4}{83}{A box plot of the \texttt {afl.margins} variable plotted in JASP}{figure.5.4}{}}
\newlabel{sec:violinplots}{{5.2.1}{83}{Violin plots~\label {sec:violinplots}}{subsection.5.2.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Violin plots~}{83}{subsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces A violin plot of the \texttt  {afl.margins} variable plotted in JASP, also showing a box plot and data points}}{84}{figure.5.5}\protected@file@percent }
\newlabel{fig:boxplot2}{{5.5}{84}{A violin plot of the \texttt {afl.margins} variable plotted in JASP, also showing a box plot and data points}{figure.5.5}{}}
\newlabel{sec:multipleboxplots}{{5.2.2}{84}{Drawing multiple boxplots~\label {sec:multipleboxplots}}{subsection.5.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Drawing multiple boxplots~}{84}{subsection.5.2.2}\protected@file@percent }
\newlabel{sec:saveimage}{{5.3}{84}{Saving image files using JASP~\label {sec:saveimage}}{section.5.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Saving image files using JASP~}{84}{section.5.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Multiple boxplots plotted in JASP, for the \texttt  {margin} by \texttt  {year} variables in the \texttt  {aflsmall2} data set}}{85}{figure.5.6}\protected@file@percent }
\newlabel{fig:boxplot3}{{5.6}{85}{Multiple boxplots plotted in JASP, for the \texttt {margin} by \texttt {year} variables in the \texttt {aflsmall2} data set}{figure.5.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Summary}{85}{section.5.4}\protected@file@percent }
\abx@aux@cite{Wilkinson2006}
\abx@aux@segm{0}{0}{Wilkinson2006}
\abx@aux@backref{18}{Wilkinson2006}{0}{86}{86}
\abx@aux@page{18}{86}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {part}{IV\hspace  {1em}Statistical theory}{87}{part.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Introduction to probability}{95}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:probability}{{6}{95}{Introduction to probability}{chapter.6}{}}
\newlabel{sec:probstats}{{6.1}{96}{How are probability and statistics different?~\label {sec:probstats}}{section.6.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.1}How are probability and statistics different?~}{96}{section.6.1}\protected@file@percent }
\newlabel{sec:probmeaning}{{6.2}{97}{What does probability mean?\label {sec:probmeaning}}{section.6.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.2}What does probability mean?}{97}{section.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}The frequentist view}{98}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}The Bayesian view}{99}{subsection.6.2.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces An illustration of how frequentist probability works. If you flip a fair coin over and over again the proportion of heads that you've seen eventually settles down and converges to the true probability of 0.5. Each panel shows four different simulated experiments. In each case we pretend we flipped a coin 1000 times and kept track of the proportion of flips that were heads as we went along. Although none of these sequences actually ended up with an exact value of .5, if we'd extended the experiment for an infinite number of coin flips they would have.}}{100}{figure.6.1}\protected@file@percent }
\newlabel{fig:frequentistprobability}{{6.1}{100}{An illustration of how frequentist probability works. If you flip a fair coin over and over again the proportion of heads that you've seen eventually settles down and converges to the true probability of 0.5. Each panel shows four different simulated experiments. In each case we pretend we flipped a coin 1000 times and kept track of the proportion of flips that were heads as we went along. Although none of these sequences actually ended up with an exact value of .5, if we'd extended the experiment for an infinite number of coin flips they would have}{figure.6.1}{}}
\abx@aux@cite{Fisher1922b}
\abx@aux@segm{0}{0}{Fisher1922b}
\abx@aux@cite{Meehl1967}
\abx@aux@segm{0}{0}{Meehl1967}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}What's the difference? And who is right?}{101}{subsection.6.2.3}\protected@file@percent }
\abx@aux@backref{19}{Fisher1922b}{0}{102}{102}
\abx@aux@page{19}{102}
\abx@aux@backref{20}{Meehl1967}{0}{102}{102}
\abx@aux@page{20}{102}
\newlabel{sec:basicprobability}{{6.3}{102}{Basic probability theory~\label {sec:basicprobability}}{section.6.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.3}Basic probability theory~}{102}{section.6.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Introducing probability distributions}{102}{subsection.6.3.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces A visual depiction of the ``trousers'' probability distribution. There are five ``elementary events'', corresponding to the five pairs of trousers that I own. Each event has some probability of occurring: this probability is a number between 0 to 1. The sum of these probabilities is 1.}}{104}{figure.6.2}\protected@file@percent }
\newlabel{fig:pantsprob}{{6.2}{104}{A visual depiction of the ``trousers'' probability distribution. There are five ``elementary events'', corresponding to the five pairs of trousers that I own. Each event has some probability of occurring: this probability is a number between 0 to 1. The sum of these probabilities is 1}{figure.6.2}{}}
\newlabel{sec:binomial}{{6.4}{104}{The binomial distribution\label {sec:binomial}}{section.6.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.4}The binomial distribution}{104}{section.6.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Some basic rules that probabilities must satisfy. You don't really need to know these rules in order to understand the analyses that we'll talk about later in the book, but they are important if you want to understand probability theory a bit more deeply.}}{105}{table.6.1}\protected@file@percent }
\newlabel{tab:probrules}{{6.1}{105}{Some basic rules that probabilities must satisfy. You don't really need to know these rules in order to understand the analyses that we'll talk about later in the book, but they are important if you want to understand probability theory a bit more deeply}{table.6.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Introducing the binomial}{105}{subsection.6.4.1}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-10}{\default{6.4}\page{105}\abspage{117}\mdf@pagevalue{105}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Formulas for the binomial and normal distributions. We don't really use these formulas for anything in this book, but they're pretty important for more advanced work, so I thought it might be best to put them here in a table, where they can't get in the way of the text. In the equation for the binomial, $X!$ is the factorial function (i.e., multiply all whole numbers from 1 to $X$), and for the normal distribution ``exp'' refers to the exponential function. If these equations don't make a lot of sense to you, don't worry too much about them. }}{105}{table.6.2}\protected@file@percent }
\newlabel{tab:distformulas}{{6.2}{105}{Formulas for the binomial and normal distributions. We don't really use these formulas for anything in this book, but they're pretty important for more advanced work, so I thought it might be best to put them here in a table, where they can't get in the way of the text. In the equation for the binomial, $X!$ is the factorial function (i.e., multiply all whole numbers from 1 to $X$), and for the normal distribution ``exp'' refers to the exponential function. If these equations don't make a lot of sense to you, don't worry too much about them}{table.6.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces The binomial distribution with size parameter of $N=20$ and an underlying success probability of $\theta = 1/6$. Each vertical bar depicts the probability of one specific outcome (i.e., one possible value of $X$). Because this is a probability distribution, each of the probabilities must be a number between 0 and 1, and the heights of the bars must sum to 1 as well.}}{106}{figure.6.3}\protected@file@percent }
\newlabel{fig:binomial1}{{6.3}{106}{The binomial distribution with size parameter of $N=20$ and an underlying success probability of $\theta = 1/6$. Each vertical bar depicts the probability of one specific outcome (i.e., one possible value of $X$). Because this is a probability distribution, each of the probabilities must be a number between 0 and 1, and the heights of the bars must sum to 1 as well}{figure.6.3}{}}
\newlabel{sec:normal}{{6.5}{107}{The normal distribution\label {sec:normal}}{section.6.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.5}The normal distribution}{107}{section.6.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Two binomial distributions, involving a scenario in which I'm flipping a fair coin, so the underlying success probability is $\theta = 1/2$. In panel (a), we assume I'm flipping the coin $N=20$ times. In panel (b) we assume that the coin is flipped $N=100$ times.}}{108}{figure.6.4}\protected@file@percent }
\newlabel{fig:binomial2}{{6.4}{108}{Two binomial distributions, involving a scenario in which I'm flipping a fair coin, so the underlying success probability is $\theta = 1/2$. In panel (a), we assume I'm flipping the coin $N=20$ times. In panel (b) we assume that the coin is flipped $N=100$ times}{figure.6.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces The normal distribution with mean $\mu = 0$ and standard deviation $\sigma = 1$. The $x$-axis corresponds to the value of some variable, and the $y$-axis tells us something about how likely we are to observe that value. However, notice that the $y$-axis is labelled ``Probability Density'' and not ``Probability''. There is a subtle and somewhat frustrating characteristic of continuous distributions that makes the $y$ axis behave a bit oddly: the height of the curve here isn't actually the probability of observing a particular $x$ value. On the other hand, it {\it  is} true that the heights of the curve tells you which $x$ values are more likely (the higher ones!). (see Section~\ref  {sec:density} for all the annoying details)}}{109}{figure.6.5}\protected@file@percent }
\newlabel{fig:normdist}{{6.5}{109}{The normal distribution with mean $\mu = 0$ and standard deviation $\sigma = 1$. The $x$-axis corresponds to the value of some variable, and the $y$-axis tells us something about how likely we are to observe that value. However, notice that the $y$-axis is labelled ``Probability Density'' and not ``Probability''. There is a subtle and somewhat frustrating characteristic of continuous distributions that makes the $y$ axis behave a bit oddly: the height of the curve here isn't actually the probability of observing a particular $x$ value. On the other hand, it {\it is} true that the heights of the curve tells you which $x$ values are more likely (the higher ones!). (see Section~\ref {sec:density} for all the annoying details)}{figure.6.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces An illustration of what happens when you change the mean of a normal distribution. The solid line depicts a normal distribution with a mean of $\mu =4$. The dashed line shows a normal distribution with a mean of $\mu =7$. In both cases, the standard deviation is $\sigma =1$. Not surprisingly, the two distributions have the same shape, but the dashed line is shifted to the right.}}{110}{figure.6.6}\protected@file@percent }
\newlabel{fig:normmean}{{6.6}{110}{An illustration of what happens when you change the mean of a normal distribution. The solid line depicts a normal distribution with a mean of $\mu =4$. The dashed line shows a normal distribution with a mean of $\mu =7$. In both cases, the standard deviation is $\sigma =1$. Not surprisingly, the two distributions have the same shape, but the dashed line is shifted to the right}{figure.6.6}{}}
\newlabel{sec:density}{{6.5.1}{110}{Probability density~\label {sec:density} \advanced }{subsection.6.5.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}Probability density~ }{110}{subsection.6.5.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces An illustration of what happens when you change the the standard deviation of a normal distribution. Both distributions plotted in this figure have a mean of $\mu = 5$, but they have different standard deviations. The solid line plots a distribution with standard deviation $\sigma =1$, and the dashed line shows a distribution with standard deviation $\sigma = 2$. As a consequence, both distributions are ``centred'' on the same spot, but the dashed line is wider than the solid one.}}{111}{figure.6.7}\protected@file@percent }
\newlabel{fig:normsd}{{6.7}{111}{An illustration of what happens when you change the the standard deviation of a normal distribution. Both distributions plotted in this figure have a mean of $\mu = 5$, but they have different standard deviations. The solid line plots a distribution with standard deviation $\sigma =1$, and the dashed line shows a distribution with standard deviation $\sigma = 2$. As a consequence, both distributions are ``centred'' on the same spot, but the dashed line is wider than the solid one}{figure.6.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces The area under the curve tells you the probability that an observation falls within a particular range. The solid lines plot normal distributions with mean $\mu =0$ and standard deviation $\sigma =1$. The shaded areas illustrate ``areas under the curve'' for two important cases. In panel a, we can see that there is a 68.3\% chance that an observation will fall within one standard deviation of the mean. In panel b, we see that there is a 95.4\% chance that an observation will fall within two standard deviations of the mean.}}{112}{figure.6.8}\protected@file@percent }
\newlabel{fig:sdnorm}{{6.8}{112}{The area under the curve tells you the probability that an observation falls within a particular range. The solid lines plot normal distributions with mean $\mu =0$ and standard deviation $\sigma =1$. The shaded areas illustrate ``areas under the curve'' for two important cases. In panel a, we can see that there is a 68.3\% chance that an observation will fall within one standard deviation of the mean. In panel b, we see that there is a 95.4\% chance that an observation will fall within two standard deviations of the mean}{figure.6.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Two more examples of the ``area under the curve idea''. There is a 15.9\% chance that an observation is one standard deviation below the mean or smaller (panel a), and a 34.1\% chance that the observation is somewhere between one standard deviation below the mean and the mean (panel b). Notice that if you add these two numbers together you get $15.9\% + 34.1\% = 50\%$. For normally distributed data, there is a 50\% chance that an observation falls below the mean. And of course that also implies that there is a 50\% chance that it falls above the mean.}}{112}{figure.6.9}\protected@file@percent }
\newlabel{fig:sdnorm2}{{6.9}{112}{Two more examples of the ``area under the curve idea''. There is a 15.9\% chance that an observation is one standard deviation below the mean or smaller (panel a), and a 34.1\% chance that the observation is somewhere between one standard deviation below the mean and the mean (panel b). Notice that if you add these two numbers together you get $15.9\% + 34.1\% = 50\%$. For normally distributed data, there is a 50\% chance that an observation falls below the mean. And of course that also implies that there is a 50\% chance that it falls above the mean}{figure.6.9}{}}
\newlabel{sec:otherdists}{{6.6}{113}{Other useful distributions~\label {sec:otherdists}}{section.6.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.6}Other useful distributions~}{113}{section.6.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces A $t$ distribution with 3 degrees of freedom (solid line). It looks similar to a normal distribution, but it's not quite the same. For comparison purposes I've plotted a standard normal distribution as the dashed line.}}{114}{figure.6.10}\protected@file@percent }
\newlabel{fig:tdist}{{6.10}{114}{A $t$ distribution with 3 degrees of freedom (solid line). It looks similar to a normal distribution, but it's not quite the same. For comparison purposes I've plotted a standard normal distribution as the dashed line}{figure.6.10}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces A $\chi ^2$ distribution with 3 degrees of freedom. Notice that the observed values must always be greater than zero, and that the distribution is pretty skewed. These are the key features of a chi-square distribution.}}{115}{figure.6.11}\protected@file@percent }
\newlabel{fig:chisqdist}{{6.11}{115}{A $\chi ^2$ distribution with 3 degrees of freedom. Notice that the observed values must always be greater than zero, and that the distribution is pretty skewed. These are the key features of a chi-square distribution}{figure.6.11}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces An $F$ distribution with 3 and 5 degrees of freedom. Qualitatively speaking, it looks pretty similar to a chi-square distribution, but they're not quite the same in general.}}{115}{figure.6.12}\protected@file@percent }
\newlabel{fig:Fdist}{{6.12}{115}{An $F$ distribution with 3 and 5 degrees of freedom. Qualitatively speaking, it looks pretty similar to a chi-square distribution, but they're not quite the same in general}{figure.6.12}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.7}Summary}{116}{section.6.7}\protected@file@percent }
\abx@aux@cite{Evans2000}
\abx@aux@segm{0}{0}{Evans2000}
\abx@aux@backref{21}{Evans2000}{0}{117}{117}
\abx@aux@page{21}{117}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {7}Estimating unknown quantities from a sample}{119}{chapter.7}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:estimation}{{7}{119}{Estimating unknown quantities from a sample}{chapter.7}{}}
\newlabel{sec:srs}{{7.1}{119}{Samples, populations and sampling~\label {sec:srs}}{section.7.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.1}Samples, populations and sampling~}{119}{section.7.1}\protected@file@percent }
\newlabel{sec:pop}{{7.1.1}{120}{Defining a population~\label {sec:pop}}{subsection.7.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Defining a population~}{120}{subsection.7.1.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Simple random sampling without replacement from a finite population}}{121}{figure.7.1}\protected@file@percent }
\newlabel{fig:srs1}{{7.1}{121}{Simple random sampling without replacement from a finite population}{figure.7.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Simple random samples}{121}{subsection.7.1.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Biased sampling without replacement from a finite population}}{122}{figure.7.2}\protected@file@percent }
\newlabel{fig:brs}{{7.2}{122}{Biased sampling without replacement from a finite population}{figure.7.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Simple random sampling {\it  with} replacement from a finite population}}{122}{figure.7.3}\protected@file@percent }
\newlabel{fig:srs2}{{7.3}{122}{Simple random sampling {\it with} replacement from a finite population}{figure.7.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Most samples are not simple random samples}{123}{subsection.7.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.4}How much does it matter if you don't have a simple random sample?}{124}{subsection.7.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.5}Population parameters and sample statistics}{125}{subsection.7.1.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces The population distribution of IQ scores (panel a) and two samples drawn randomly from it. In panel b we have a sample of 100 observations, and panel c we have a sample of 10,000 observations.}}{126}{figure.7.4}\protected@file@percent }
\newlabel{fig:IQdist}{{7.4}{126}{The population distribution of IQ scores (panel a) and two samples drawn randomly from it. In panel b we have a sample of 100 observations, and panel c we have a sample of 10,000 observations}{figure.7.4}{}}
\newlabel{sec:lawlargenumbers}{{7.2}{126}{The law of large numbers~\label {sec:lawlargenumbers}}{section.7.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.2}The law of large numbers~}{126}{section.7.2}\protected@file@percent }
\abx@aux@cite{Stigler1986}
\abx@aux@segm{0}{0}{Stigler1986}
\abx@aux@backref{22}{Stigler1986}{0}{127}{127}
\abx@aux@page{22}{127}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces A random sample drawn from a normal distribution using JASP}}{128}{figure.7.5}\protected@file@percent }
\newlabel{fig:iqsim}{{7.5}{128}{A random sample drawn from a normal distribution using JASP}{figure.7.5}{}}
\abx@aux@cite{Keynes1923}
\abx@aux@segm{0}{0}{Keynes1923}
\newlabel{sec:samplesandclt}{{7.3}{129}{Sampling distributions and the central limit theorem~\label {sec:samplesandclt}}{section.7.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.3}Sampling distributions and the central limit theorem~}{129}{section.7.3}\protected@file@percent }
\abx@aux@backref{23}{Keynes1923}{0}{129}{129}
\abx@aux@page{23}{129}
\newlabel{sec:samplingdists}{{7.3.1}{129}{Sampling distribution of the mean~\label {sec:samplingdists}}{subsection.7.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Sampling distribution of the mean~}{129}{subsection.7.3.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Using JASP to draw a random sample of 5 from a normal distribution with $\mu =100$ and $\sigma =15$.}}{130}{figure.7.6}\protected@file@percent }
\newlabel{fig:IQsample}{{7.6}{130}{Using JASP to draw a random sample of 5 from a normal distribution with $\mu =100$ and $\sigma =15$}{figure.7.6}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Ten replications of the IQ experiment, each with a sample size of $N=5$.}}{131}{table.7.1}\protected@file@percent }
\newlabel{tab:replications}{{7.1}{131}{Ten replications of the IQ experiment, each with a sample size of $N=5$}{table.7.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Sampling distributions exist for any sample statistic!}{131}{subsection.7.3.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces The sampling distribution of the mean for the ``five IQ scores experiment''. If you sample 5 people at random and calculate their {\it  average} IQ you'll almost certainly get a number between 80 and 120, even though there are quite a lot of individuals who have IQs above 120 or below 80. For comparison, the black line plots the population distribution of IQ scores.}}{132}{figure.7.7}\protected@file@percent }
\newlabel{fig:sampdistmean}{{7.7}{132}{The sampling distribution of the mean for the ``five IQ scores experiment''. If you sample 5 people at random and calculate their {\it average} IQ you'll almost certainly get a number between 80 and 120, even though there are quite a lot of individuals who have IQs above 120 or below 80. For comparison, the black line plots the population distribution of IQ scores}{figure.7.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces The sampling distribution of the {\it  maximum} for the ``five IQ scores experiment''. If you sample 5 people at random and select the one with the highest IQ score you'll probably see someone with an IQ between 100 and 140.}}{132}{figure.7.8}\protected@file@percent }
\newlabel{fig:sampdistmax}{{7.8}{132}{The sampling distribution of the {\it maximum} for the ``five IQ scores experiment''. If you sample 5 people at random and select the one with the highest IQ score you'll probably see someone with an IQ between 100 and 140}{figure.7.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces An illustration of the how sampling distribution of the mean depends on sample size. In each panel I generated 10,000 samples of IQ data and calculated the mean IQ observed within each of these data sets. The histograms in these plots show the distribution of these means (i.e., the sampling distribution of the mean). Each individual IQ score was drawn from a normal distribution with mean 100 and standard deviation 15, which is shown as the solid black line. In panel a, each data set contained only a single observation, so the mean of each sample is just one person's IQ score. As a consequence, the sampling distribution of the mean is of course identical to the population distribution of IQ scores. However, when we raise the sample size to 2 the mean of any one sample tends to be closer to the population mean than a one person's IQ score, and so the histogram (i.e., the sampling distribution) is a bit narrower than the population distribution. By the time we raise the sample size to 10 (panel c), we can see that the distribution of sample means tend to be fairly tightly clustered around the true population mean.}}{133}{figure.7.9}\protected@file@percent }
\newlabel{fig:IQsamp}{{7.9}{133}{An illustration of the how sampling distribution of the mean depends on sample size. In each panel I generated 10,000 samples of IQ data and calculated the mean IQ observed within each of these data sets. The histograms in these plots show the distribution of these means (i.e., the sampling distribution of the mean). Each individual IQ score was drawn from a normal distribution with mean 100 and standard deviation 15, which is shown as the solid black line. In panel a, each data set contained only a single observation, so the mean of each sample is just one person's IQ score. As a consequence, the sampling distribution of the mean is of course identical to the population distribution of IQ scores. However, when we raise the sample size to 2 the mean of any one sample tends to be closer to the population mean than a one person's IQ score, and so the histogram (i.e., the sampling distribution) is a bit narrower than the population distribution. By the time we raise the sample size to 10 (panel c), we can see that the distribution of sample means tend to be fairly tightly clustered around the true population mean}{figure.7.9}{}}
\newlabel{sec:clt}{{7.3.3}{133}{The central limit theorem~\label {sec:clt}}{subsection.7.3.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}The central limit theorem~}{133}{subsection.7.3.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces A demonstration of the central limit theorem. In panel a, we have a non-normal population distribution, and panels b-d show the sampling distribution of the mean for samples of size 2,4 and 8 for data drawn from the distribution in panel a. As you can see, even though the original population distribution is non-normal the sampling distribution of the mean becomes pretty close to normal by the time you have a sample of even 4 observations. }}{135}{figure.7.10}\protected@file@percent }
\newlabel{fig:cltdemo}{{7.10}{135}{A demonstration of the central limit theorem. In panel a, we have a non-normal population distribution, and panels b-d show the sampling distribution of the mean for samples of size 2,4 and 8 for data drawn from the distribution in panel a. As you can see, even though the original population distribution is non-normal the sampling distribution of the mean becomes pretty close to normal by the time you have a sample of even 4 observations}{figure.7.10}{}}
\newlabel{sec:pointestimates}{{7.4}{136}{Estimating population parameters~\label {sec:pointestimates}}{section.7.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.4}Estimating population parameters~}{136}{section.7.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Estimating the population mean}{137}{subsection.7.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Estimating the population standard deviation}{137}{subsection.7.4.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.11}{\ignorespaces The sampling distribution of the sample standard deviation for a ``two IQ scores'' experiment. The true population standard deviation is 15 (dashed line), but as you can see from the histogram the vast majority of experiments will produce a much smaller sample standard deviation than this. On average, this experiment would produce a sample standard deviation of only 8.5, well below the true value! In other words, the sample standard deviation is a {\it  biased} estimate of the population standard deviation.}}{139}{figure.7.11}\protected@file@percent }
\newlabel{fig:sampdistsd}{{7.11}{139}{The sampling distribution of the sample standard deviation for a ``two IQ scores'' experiment. The true population standard deviation is 15 (dashed line), but as you can see from the histogram the vast majority of experiments will produce a much smaller sample standard deviation than this. On average, this experiment would produce a sample standard deviation of only 8.5, well below the true value! In other words, the sample standard deviation is a {\it biased} estimate of the population standard deviation}{figure.7.11}{}}
\zref@newlabel{mdf@pagelabel-11}{\default{7.4}\page{140}\abspage{152}\mdf@pagevalue{140}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.12}{\ignorespaces An illustration of the fact that the sample mean is an unbiased estimator of the population mean (panel a), but the sample standard deviation is a biased estimator of the population standard deviation (panel b). For the figure I generated 10,000 simulated data sets with 1 observation each, 10,000 more with 2 observations, and so on up to a sample size of 10. Each data set consisted of fake IQ data, that is the data were normally distributed with a true population mean of 100 and standard deviation 15. {\it  On average}, the sample means turn out to be 100, regardless of sample size (panel a). However, the sample standard deviations turn out to be systematically too small (panel b), especially for small sample sizes.}}{141}{figure.7.12}\protected@file@percent }
\newlabel{fig:estimatorbias}{{7.12}{141}{An illustration of the fact that the sample mean is an unbiased estimator of the population mean (panel a), but the sample standard deviation is a biased estimator of the population standard deviation (panel b). For the figure I generated 10,000 simulated data sets with 1 observation each, 10,000 more with 2 observations, and so on up to a sample size of 10. Each data set consisted of fake IQ data, that is the data were normally distributed with a true population mean of 100 and standard deviation 15. {\it On average}, the sample means turn out to be 100, regardless of sample size (panel a). However, the sample standard deviations turn out to be systematically too small (panel b), especially for small sample sizes}{figure.7.12}{}}
\newlabel{sec:ci}{{7.5}{143}{Estimating a confidence interval\label {sec:ci}}{section.7.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.5}Estimating a confidence interval}{143}{section.7.5}\protected@file@percent }
\zref@newlabel{mdf@pagelabel-12}{\default{7.5}\page{144}\abspage{156}\mdf@pagevalue{144}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}A slight mistake in the formula}{144}{subsection.7.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Interpreting a confidence interval}{145}{subsection.7.5.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7.13}{\ignorespaces 95\% confidence intervals. The top (panel a) shows 50 simulated replications of an experiment in which we measure the IQs of 10 people. The dot marks the location of the sample mean and the line shows the 95\% confidence interval. In total 47 of the 50 confidence intervals do contain the true mean (i.e., 100), but the three intervals marked with asterisks do not. The lower graph (panel b) shows a similar simulation, but this time we simulate replications of an experiment that measures the IQs of 25 people.}}{146}{figure.7.13}\protected@file@percent }
\newlabel{fig:cirep}{{7.13}{146}{95\% confidence intervals. The top (panel a) shows 50 simulated replications of an experiment in which we measure the IQs of 10 people. The dot marks the location of the sample mean and the line shows the 95\% confidence interval. In total 47 of the 50 confidence intervals do contain the true mean (i.e., 100), but the three intervals marked with asterisks do not. The lower graph (panel b) shows a similar simulation, but this time we simulate replications of an experiment that measures the IQs of 25 people}{figure.7.13}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.3}Calculating confidence intervals in jamovi}{147}{subsection.7.5.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7.6}Summary}{147}{section.7.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {8}References}{149}{chapter.8}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@page{24}{149}
\abx@aux@page{25}{149}
\abx@aux@page{26}{149}
\abx@aux@page{27}{149}
\abx@aux@page{28}{149}
\abx@aux@page{29}{149}
\abx@aux@page{30}{149}
\abx@aux@page{31}{149}
\abx@aux@page{32}{149}
\abx@aux@page{33}{149}
\abx@aux@page{34}{149}
\abx@aux@page{35}{149}
\abx@aux@page{36}{149}
\abx@aux@page{37}{149}
\abx@aux@page{38}{149}
\abx@aux@page{39}{150}
\abx@aux@page{40}{150}
\abx@aux@page{41}{150}
\abx@aux@page{42}{150}
\abx@aux@page{43}{150}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{Adair1984}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Bickel1975}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Campbell1963}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Ellman2002}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Evans1983}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Evans2000}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Fisher1922b}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Gelman2014}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Hothersall2004}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hrobjartsson2010}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Ioannidis2005}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Kahneman1973}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Keynes1923}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Kuhberger2014}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Meehl1967}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Pfungst1911}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Rosenthal1966}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Stevens1946}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Stigler1986}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Wilkinson2006}{nyt/global//global/global}
